{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzoTkyFIv2dI"
      },
      "source": [
        "## **About Aweshome**\n",
        "\n",
        "Aweshome is a chatbot created by implementing machine learning in it. Its manufacture is carried out as an additional feature that will complement the smart home application created that also called Aweshome.\n",
        "This application has a motto:\n",
        "\n",
        "***Aweshome: Make your home smart and awesome ***\n",
        "\n",
        "The chatbot feature will help users explicitly manage the appliances in their house, as well as to know the condition of their house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lIK8Wk4w-L8"
      },
      "source": [
        "# **Steps to create Aweshome Chatbot**\n",
        "\n",
        "The following is an overview of the steps taken to create an Aweshome chatbot:\n",
        "1. Prepare the required packages, including the Deep Learning, Tensorflow, Keras, Pickle, and NLTK (Natural Language Processing Toolkit) libraries.\n",
        "2. Prepare a dataset in the form of a collection of user input and output that must be displayed in response to the Aweshome chatbot. The file is saved in JSON type and is named \"intents.\"\n",
        "3. Perform data preparation including import required packages, load the JSON file and extract the required data.\n",
        "4. Creating models including training and testing models.\n",
        "5. Integrating Aweshome chatbot with application.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lk2kSK3m8bN"
      },
      "outputs": [],
      "source": [
        "#code for import the packages\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM , Dense,GlobalMaxPooling1D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x8Y8oo-n8qL"
      },
      "outputs": [],
      "source": [
        "#code for import the dataset that have been created in JSON format\n",
        "with open('intents.json') as content:\n",
        "  data1 = json.load(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWSsL8pzoDHv"
      },
      "outputs": [],
      "source": [
        "#code for getting all the data to lists\n",
        "tags = []\n",
        "patterns = []\n",
        "responses={}\n",
        "for intent in data1['intents']:\n",
        "  responses[intent['tag']]=intent['responses']\n",
        "  for lines in intent['patterns']:\n",
        "    patterns.append(lines)\n",
        "    tags.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyFItEYXoECF"
      },
      "outputs": [],
      "source": [
        "#code for convert the data to dataframe\n",
        "data = pd.DataFrame({\"inputs\":patterns,\n",
        "                     \"tags\":tags})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KREe0b5soGCg"
      },
      "outputs": [],
      "source": [
        "#code for print the data and get data sample\n",
        "data\n",
        "data = data.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tU8j9ijloKPd",
        "outputId": "1f3571b6-a8c2-4b4a-cc55-b4623ec5111b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                inputs            tags\n",
              "122                           lampunya sudah dimatikan      lampu_mati\n",
              "221                      keluarkan jemurannya sekarang  jemuran_keluar\n",
              "161                buat pintu menjadi terbuka sekarang      pintu_buka\n",
              "53      bagaimana kondisi kompor gas di rumah saat ini   kondisi_rumah\n",
              "170    bagaimana kondisi pintu saat ini tolong ditutup     pintu_tutup\n",
              "..                                                 ...             ...\n",
              "216                               keluarkan jemurannya  jemuran_keluar\n",
              "77                                        sembah nuwun    terima_kasih\n",
              "10                                                 cek          salam1\n",
              "217  apakah sedang turun hujan jemurannya tolong di...  jemuran_keluar\n",
              "226                   apakah pakaian sudah dikeluarkan  jemuran_keluar\n",
              "\n",
              "[238 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7883eb09-f665-4daf-a83f-5ff6cef908d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>lampunya sudah dimatikan</td>\n",
              "      <td>lampu_mati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>keluarkan jemurannya sekarang</td>\n",
              "      <td>jemuran_keluar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>buat pintu menjadi terbuka sekarang</td>\n",
              "      <td>pintu_buka</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>bagaimana kondisi kompor gas di rumah saat ini</td>\n",
              "      <td>kondisi_rumah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>bagaimana kondisi pintu saat ini tolong ditutup</td>\n",
              "      <td>pintu_tutup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>keluarkan jemurannya</td>\n",
              "      <td>jemuran_keluar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>sembah nuwun</td>\n",
              "      <td>terima_kasih</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>cek</td>\n",
              "      <td>salam1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>apakah sedang turun hujan jemurannya tolong di...</td>\n",
              "      <td>jemuran_keluar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>apakah pakaian sudah dikeluarkan</td>\n",
              "      <td>jemuran_keluar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>238 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7883eb09-f665-4daf-a83f-5ff6cef908d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7883eb09-f665-4daf-a83f-5ff6cef908d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7883eb09-f665-4daf-a83f-5ff6cef908d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "#code for remove punctuations\n",
        "import string\n",
        "data['inputs'] = data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "data['inputs'] = data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXrgBPxooMSn"
      },
      "outputs": [],
      "source": [
        "#code for tokenize the data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(data['inputs'])\n",
        "train = tokenizer.texts_to_sequences(data['inputs'])\n",
        "#code for apply padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(train)\n",
        "\n",
        "#code for encode the outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lbl_encoder = LabelEncoder()\n",
        "y_train = lbl_encoder.fit_transform(data['tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEvG_oKcoOpU",
        "outputId": "94091faa-4caa-4782-f780-2f8374b9e9b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ],
      "source": [
        "input_shape = x_train.shape[1]\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK1Dj0T3oQ4E",
        "outputId": "585b1ee4-c88a-48d4-8a65-0bed307b7c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique words :  195\n",
            "output length:  14\n"
          ]
        }
      ],
      "source": [
        "#code for define vocabulary\n",
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"number of unique words : \",vocabulary)\n",
        "output_length = lbl_encoder.classes_.shape[0]\n",
        "print(\"output length: \",output_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import string\n",
        "import random\n",
        "\n",
        "def chat(user_text, kondisiRumah_array):\n",
        "  texts_p = []\n",
        "  kondisiLampu = kondisiRumah_array[0] \n",
        "  kondisiPintu = kondisiRumah_array[1] \n",
        "  kondisiJemuran = kondisiRumah_array[2] \n",
        "  kondisiGas = kondisiRumah_array[3] \n",
        "  # Check kondisi lampu\n",
        "  if kondisiLampu==False:\n",
        "    kondisiLampu='mati'\n",
        "  else:\n",
        "    kondisiLampu='nyala'\n",
        "    # Check kondisi pintu\n",
        "  if kondisiPintu==False:\n",
        "    kondisiPintu='terbuka'\n",
        "  else:\n",
        "    kondisiPintu='terkunci'\n",
        "  # Check kondisi jemuran\n",
        "  if kondisiJemuran==False:\n",
        "    kondisiJemuran='kehujanan'\n",
        "  else:\n",
        "    kondisiJemuran='aman'\n",
        "  # Check kondisi gas\n",
        "  if kondisiGas==False:\n",
        "    kondisiGas='mati'\n",
        "  else:\n",
        "    kondisiGas='nyala'\n",
        "\n",
        "  #removing punctuation and converting to lowercase\n",
        "  prediction_input = [letters.lower() for letters in user_text if letters not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "\n",
        "  #tokenizing and padding\n",
        "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input],input_shape)\n",
        "\n",
        "  #getting output from model\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "  response_tag = lbl_encoder.inverse_transform([output])[0]\n",
        "\n",
        "  #finding the right tag and predicting\n",
        "  response_tag = lbl_encoder.inverse_transform([output])[0]\n",
        "  if response_tag == \"perpisahan\":\n",
        "    print(\"Aweshome : \",random.choice(responses['perpisahan']))\n",
        "  elif response_tag == \"kondisi_rumah\":\n",
        "    #lampu, pintu, jemuran, gas = getSensor()\n",
        "    kondisiRumah = []\n",
        "    print(\"Aweshome: kondisi lampu\", kondisiLampu, \"kondisi pintu\", kondisiPintu, \"kondisi jemuran\", kondisiJemuran, \"kondisi gas\", kondisiGas)\n",
        "    text = input(\"You: \")\n",
        "    chat(text, kondisiRumah_array)\n",
        "  else:\n",
        "    print(\"Aweshome : \",random.choice(responses[response_tag]))\n",
        "    text = input(\"You: \")\n",
        "    chat(text, kondisiRumah_array) "
      ],
      "metadata": {
        "id": "CRy8dd0I7OHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B4NhvHCoVXk",
        "outputId": "f8fdc99a-d7ea-474c-e059-4ebe2eadce83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 11)]              0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 11, 10)            1960      \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 11, 12)            1104      \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 11, 12)            1200      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 132)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 14)                1862      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,126\n",
            "Trainable params: 6,126\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#code for create the model\n",
        "\n",
        "i = Input(shape=(input_shape,))\n",
        "x = Embedding(vocabulary+1,10)(i)\n",
        "x = LSTM(12,return_sequences=True)(x)\n",
        "x = LSTM(12,return_sequences=True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(output_length,activation=\"softmax\")(x)\n",
        "model  = tf.keras.Model(i,x)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO1_j36BoXzc"
      },
      "outputs": [],
      "source": [
        "#code for compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xED3qGBooYR9",
        "outputId": "ac38609e-4a27-4213-ec59-2052c400f4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 4s 14ms/step - loss: 2.6359 - accuracy: 0.0798\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.6252 - accuracy: 0.1218\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.6093 - accuracy: 0.1218\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.5837 - accuracy: 0.1218\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.5486 - accuracy: 0.1218\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.5112 - accuracy: 0.1303\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.5096 - accuracy: 0.1387\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.4984 - accuracy: 0.1387\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.4949 - accuracy: 0.1387\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.4901 - accuracy: 0.1387\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.4845 - accuracy: 0.1387\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.4818 - accuracy: 0.1387\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.4797 - accuracy: 0.1429\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.4743 - accuracy: 0.1387\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 2.4679 - accuracy: 0.1387\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.4622 - accuracy: 0.1387\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.4507 - accuracy: 0.1387\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.4393 - accuracy: 0.1387\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.4214 - accuracy: 0.1429\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.4009 - accuracy: 0.1555\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3715 - accuracy: 0.1681\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3297 - accuracy: 0.1891\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.2847 - accuracy: 0.1891\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.2341 - accuracy: 0.2059\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.1772 - accuracy: 0.2311\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.1288 - accuracy: 0.2269\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.0832 - accuracy: 0.2815\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.0314 - accuracy: 0.3151\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9790 - accuracy: 0.3319\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9312 - accuracy: 0.3445\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.8890 - accuracy: 0.3697\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.8583 - accuracy: 0.3655\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.8175 - accuracy: 0.3697\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.7667 - accuracy: 0.4160\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.7156 - accuracy: 0.4370\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.6681 - accuracy: 0.4454\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.6189 - accuracy: 0.4706\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.5738 - accuracy: 0.4706\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.5314 - accuracy: 0.4916\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.4934 - accuracy: 0.4748\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.4465 - accuracy: 0.5000\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.4081 - accuracy: 0.5042\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.3618 - accuracy: 0.5378\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3285 - accuracy: 0.5840\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.2828 - accuracy: 0.5504\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2558 - accuracy: 0.6008\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2215 - accuracy: 0.5882\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1806 - accuracy: 0.6345\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.1613 - accuracy: 0.5924\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.1223 - accuracy: 0.6050\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0828 - accuracy: 0.6345\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0594 - accuracy: 0.6513\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0263 - accuracy: 0.6597\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.0069 - accuracy: 0.6555\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9783 - accuracy: 0.6681\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.9571 - accuracy: 0.6597\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9472 - accuracy: 0.6807\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.9265 - accuracy: 0.6807\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9068 - accuracy: 0.7101\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8888 - accuracy: 0.6975\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.8628 - accuracy: 0.7059\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8398 - accuracy: 0.7059\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8305 - accuracy: 0.7143\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.8274 - accuracy: 0.7185\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8041 - accuracy: 0.7269\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7839 - accuracy: 0.7479\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.7622 - accuracy: 0.7395\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.7526 - accuracy: 0.7479\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.7375 - accuracy: 0.7521\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7290 - accuracy: 0.7647\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7134 - accuracy: 0.7689\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.7012 - accuracy: 0.7773\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.6856 - accuracy: 0.7731\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6668 - accuracy: 0.8151\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.6576 - accuracy: 0.7983\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.6532 - accuracy: 0.8193\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6292 - accuracy: 0.8319\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6284 - accuracy: 0.8277\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.6156 - accuracy: 0.8235\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5989 - accuracy: 0.8613\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.6027 - accuracy: 0.8319\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5805 - accuracy: 0.8529\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5627 - accuracy: 0.8908\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5554 - accuracy: 0.9034\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5430 - accuracy: 0.8824\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5313 - accuracy: 0.8866\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5197 - accuracy: 0.9076\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.5127 - accuracy: 0.9076\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5058 - accuracy: 0.9076\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5072 - accuracy: 0.9286\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5058 - accuracy: 0.9076\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.4867 - accuracy: 0.8992\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4665 - accuracy: 0.9328\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4535 - accuracy: 0.9454\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4430 - accuracy: 0.9160\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4332 - accuracy: 0.9202\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4252 - accuracy: 0.9580\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4215 - accuracy: 0.9454\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4227 - accuracy: 0.9538\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.4016 - accuracy: 0.9580\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3960 - accuracy: 0.9706\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3872 - accuracy: 0.9622\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3793 - accuracy: 0.9706\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.3685 - accuracy: 0.9664\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3604 - accuracy: 0.9748\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3547 - accuracy: 0.9748\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3492 - accuracy: 0.9748\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.3432 - accuracy: 0.9664\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.3343 - accuracy: 0.9664\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.3310 - accuracy: 0.9706\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3257 - accuracy: 0.9664\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.3166 - accuracy: 0.9706\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.3134 - accuracy: 0.9748\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3068 - accuracy: 0.9664\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3087 - accuracy: 0.9748\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3040 - accuracy: 0.9748\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.3069 - accuracy: 0.9664\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.2904 - accuracy: 0.9748\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2815 - accuracy: 0.9790\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2794 - accuracy: 0.9790\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2720 - accuracy: 0.9706\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.2661 - accuracy: 0.9790\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.2620 - accuracy: 0.9748\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.2555 - accuracy: 0.9790\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.2519 - accuracy: 0.9790\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2501 - accuracy: 0.9748\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.2507 - accuracy: 0.9790\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2475 - accuracy: 0.9706\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2392 - accuracy: 0.9790\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.2326 - accuracy: 0.9790\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.2300 - accuracy: 0.9790\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2241 - accuracy: 0.9790\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.2217 - accuracy: 0.9790\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2175 - accuracy: 0.9790\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.2177 - accuracy: 0.9790\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2116 - accuracy: 0.9790\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.2089 - accuracy: 0.9790\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2062 - accuracy: 0.9790\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2039 - accuracy: 0.9790\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.2086 - accuracy: 0.9748\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2016 - accuracy: 0.9790\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1940 - accuracy: 0.9790\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.1917 - accuracy: 0.9790\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1886 - accuracy: 0.9790\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.1873 - accuracy: 0.9790\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.1826 - accuracy: 0.9790\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1789 - accuracy: 0.9790\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1772 - accuracy: 0.9790\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.1750 - accuracy: 0.9790\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1748 - accuracy: 0.9790\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.1715 - accuracy: 0.9790\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.1668 - accuracy: 0.9790\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.1650 - accuracy: 0.9790\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1626 - accuracy: 0.9790\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.1600 - accuracy: 0.9790\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1615 - accuracy: 0.9790\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1576 - accuracy: 0.9790\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.1573 - accuracy: 0.9790\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.1526 - accuracy: 0.9790\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1514 - accuracy: 0.9790\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1496 - accuracy: 0.9790\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1521 - accuracy: 0.9832\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1547 - accuracy: 0.9832\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1552 - accuracy: 0.9790\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.1444 - accuracy: 0.9790\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1413 - accuracy: 0.9790\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.1381 - accuracy: 0.9790\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.1365 - accuracy: 0.9790\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1343 - accuracy: 0.9790\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1354 - accuracy: 0.9832\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1411 - accuracy: 0.9874\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1345 - accuracy: 0.9874\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1317 - accuracy: 0.9790\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1270 - accuracy: 0.9790\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.1244 - accuracy: 0.9790\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1236 - accuracy: 0.9790\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1235 - accuracy: 0.9790\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1211 - accuracy: 0.9790\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1195 - accuracy: 0.9790\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1171 - accuracy: 0.9874\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.1156 - accuracy: 0.9874\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.1173 - accuracy: 0.9874\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1145 - accuracy: 0.9874\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.1125 - accuracy: 0.9874\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1123 - accuracy: 0.9874\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.1104 - accuracy: 0.9874\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1089 - accuracy: 0.9874\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1088 - accuracy: 0.9832\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1100 - accuracy: 0.9790\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1064 - accuracy: 0.9874\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1042 - accuracy: 0.9790\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1041 - accuracy: 0.9874\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1031 - accuracy: 0.9916\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1022 - accuracy: 0.9874\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.1000 - accuracy: 0.9874\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0979 - accuracy: 0.9874\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0980 - accuracy: 0.9916\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0959 - accuracy: 0.9874\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0962 - accuracy: 0.9916\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0945 - accuracy: 0.9916\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0931 - accuracy: 0.9874\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0917 - accuracy: 0.9874\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0919 - accuracy: 0.9916\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0926 - accuracy: 0.9874\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0912 - accuracy: 0.9874\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0891 - accuracy: 0.9874\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0876 - accuracy: 0.9874\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0865 - accuracy: 0.9916\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0858 - accuracy: 0.9916\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0864 - accuracy: 0.9874\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0850 - accuracy: 0.9874\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0827 - accuracy: 0.9916\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0820 - accuracy: 0.9874\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0814 - accuracy: 0.9916\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0808 - accuracy: 0.9916\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0797 - accuracy: 0.9916\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0799 - accuracy: 0.9916\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0804 - accuracy: 0.9916\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0802 - accuracy: 0.9874\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0794 - accuracy: 0.9916\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0771 - accuracy: 0.9874\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0749 - accuracy: 0.9916\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0741 - accuracy: 0.9916\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0735 - accuracy: 0.9916\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0728 - accuracy: 0.9916\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0719 - accuracy: 0.9916\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0714 - accuracy: 0.9916\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0701 - accuracy: 0.9958\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0700 - accuracy: 0.9958\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0703 - accuracy: 0.9916\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0715 - accuracy: 0.9916\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0687 - accuracy: 0.9958\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0684 - accuracy: 0.9916\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0666 - accuracy: 0.9958\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0657 - accuracy: 0.9958\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9958\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0652 - accuracy: 0.9958\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0653 - accuracy: 0.9916\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0655 - accuracy: 0.9958\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0635 - accuracy: 0.9958\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0625 - accuracy: 0.9958\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0626 - accuracy: 0.9958\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0622 - accuracy: 0.9958\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0612 - accuracy: 0.9958\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0605 - accuracy: 0.9958\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0601 - accuracy: 0.9958\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0595 - accuracy: 0.9958\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0594 - accuracy: 0.9958\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0579 - accuracy: 0.9958\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0584 - accuracy: 0.9958\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0569 - accuracy: 0.9958\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0572 - accuracy: 0.9958\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0564 - accuracy: 0.9958\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0560 - accuracy: 0.9958\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0553 - accuracy: 0.9958\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0555 - accuracy: 0.9958\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0541 - accuracy: 0.9958\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0537 - accuracy: 0.9958\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0531 - accuracy: 0.9958\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0530 - accuracy: 0.9958\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0536 - accuracy: 0.9958\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0530 - accuracy: 0.9958\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0520 - accuracy: 0.9958\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0510 - accuracy: 0.9958\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0510 - accuracy: 0.9958\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0508 - accuracy: 0.9958\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0501 - accuracy: 0.9958\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0488 - accuracy: 0.9958\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0492 - accuracy: 0.9958\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0489 - accuracy: 0.9958\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0490 - accuracy: 0.9958\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0513 - accuracy: 0.9916\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0500 - accuracy: 0.9958\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0495 - accuracy: 0.9916\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0462 - accuracy: 0.9958\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0463 - accuracy: 0.9916\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0465 - accuracy: 0.9958\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9958\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0475 - accuracy: 0.9958\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0468 - accuracy: 0.9958\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0482 - accuracy: 0.9958\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0448 - accuracy: 0.9958\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0441 - accuracy: 0.9958\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0432 - accuracy: 0.9958\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0432 - accuracy: 0.9958\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0424 - accuracy: 0.9958\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0422 - accuracy: 0.9916\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0412 - accuracy: 0.9958\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0417 - accuracy: 0.9958\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0408 - accuracy: 0.9958\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0417 - accuracy: 0.9958\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0404 - accuracy: 0.9958\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0397 - accuracy: 0.9958\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9958\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0396 - accuracy: 0.9958\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9958\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0391 - accuracy: 0.9958\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0384 - accuracy: 0.9958\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 0.9958\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0375 - accuracy: 0.9958\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0380 - accuracy: 0.9958\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0377 - accuracy: 0.9916\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0378 - accuracy: 0.9958\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9958\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0366 - accuracy: 0.9958\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0358 - accuracy: 0.9958\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0356 - accuracy: 0.9958\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0357 - accuracy: 0.9958\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0352 - accuracy: 0.9958\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0348 - accuracy: 0.9958\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0347 - accuracy: 0.9958\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9958\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0344 - accuracy: 0.9958\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0342 - accuracy: 0.9958\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0339 - accuracy: 0.9958\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0335 - accuracy: 0.9958\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0331 - accuracy: 0.9958\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0335 - accuracy: 0.9916\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0326 - accuracy: 0.9958\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0331 - accuracy: 0.9958\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0328 - accuracy: 0.9958\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0319 - accuracy: 0.9958\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9958\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 0.9958\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0325 - accuracy: 0.9916\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0321 - accuracy: 0.9916\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9958\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0305 - accuracy: 0.9958\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9958\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9958\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9958\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9958\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0295 - accuracy: 0.9958\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.9958\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9958\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9958\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0314 - accuracy: 0.9958\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9958\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0291 - accuracy: 0.9958\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0285 - accuracy: 0.9958\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0280 - accuracy: 0.9916\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 0.9916\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0278 - accuracy: 0.9958\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0279 - accuracy: 0.9916\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0273 - accuracy: 0.9916\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.9958\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9958\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0271 - accuracy: 0.9958\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9958\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9958\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9916\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0273 - accuracy: 0.9916\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 0.9958\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0260 - accuracy: 0.9958\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.9958\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0260 - accuracy: 0.9958\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0259 - accuracy: 0.9916\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9958\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0269 - accuracy: 0.9958\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0252 - accuracy: 0.9958\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.9958\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0259 - accuracy: 0.9958\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9958\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9958\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9958\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0249 - accuracy: 0.9958\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9958\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0243 - accuracy: 0.9958\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9958\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 0.9958\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0238 - accuracy: 0.9958\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.9958\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 0.9916\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0234 - accuracy: 0.9916\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9916\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9958\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9958\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9958\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 0.9958\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9958\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9916\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9916\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9958\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0217 - accuracy: 0.9958\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9958\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9916\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0220 - accuracy: 0.9958\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9958\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9958\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0213 - accuracy: 0.9958\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0216 - accuracy: 0.9916\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9958\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0211 - accuracy: 0.9958\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9958\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9958\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9916\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0209 - accuracy: 0.9958\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0205 - accuracy: 0.9958\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0204 - accuracy: 0.9958\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9958\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9958\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0199 - accuracy: 0.9958\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0202 - accuracy: 0.9958\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 0.9916\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 0.9958\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9958\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.9958\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0199 - accuracy: 0.9958\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9958\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9958\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9916\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9958\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9958\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9958\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0187 - accuracy: 0.9916\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9958\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9958\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9958\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9958\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9958\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9916\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0182 - accuracy: 0.9958\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0182 - accuracy: 0.9958\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9958\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 0.9916\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9958\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9958\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 0.9958\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9958\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9916\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9958\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9958\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.9958\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0178 - accuracy: 0.9916\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.9958\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9958\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9958\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.9916\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0172 - accuracy: 0.9958\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9916\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9958\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9958\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9958\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9958\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9958\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9958\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0165 - accuracy: 0.9958\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 0.9958\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9958\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0164 - accuracy: 0.9916\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9916\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9958\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9916\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9958\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 0.9958\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9958\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9958\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 0.9958\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9916\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0156 - accuracy: 0.9958\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9916\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0152 - accuracy: 0.9958\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9916\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0158 - accuracy: 0.9958\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9958\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9958\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9958\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 0.9916\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9916\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9958\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9958\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9916\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9916\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0150 - accuracy: 0.9958\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9958\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9916\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9916\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0152 - accuracy: 0.9916\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9958\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 0.9958\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9958\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0141 - accuracy: 0.9958\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 0.9958\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9958\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 0.9958\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.9958\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 0.9958\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0143 - accuracy: 0.9958\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9916\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9958\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0140 - accuracy: 0.9958\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9916\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9958\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 0.9958\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9958\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 0.9958\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.9958\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9958\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 0.9958\n"
          ]
        }
      ],
      "source": [
        "#code for train the model\n",
        "train = model.fit(x_train,y_train,epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "BetA34bjoaLc",
        "outputId": "e34d855d-bfe9-4cfc-abc9-6cfd15ada62d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training Accuracy Model')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#code for plot accuracy model\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(train.history['accuracy'],label='training set accuracy',color='blue')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training Accuracy Model')\n",
        "\n",
        "#code for plot loss model\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(train.history['loss'],label='training set loss',color='red')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training Accuracy Model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WndclXJM4Nf",
        "outputId": "cf8efac6-cedc-431b-b4ed-404b0c5792d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: chat_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: chat_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8e13396a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8e187c9590> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "#code for save the model\n",
        "model.save(\"chat_model\")\n",
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
        "\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcPjxZXaA0HT"
      },
      "outputs": [],
      "source": [
        "# code for save model to h5 format \n",
        "model.save('./model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPeTcsoxgExB",
        "outputId": "ee59fe09-fc95-4b64-ebec-c58a310d24f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpwwbxhq9p/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpwwbxhq9p/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31008"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Code for save to tflite format\n",
        "from tensorflow import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.experimental_new_converter=True\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "tfmodel = converter.convert()\n",
        "open('model.tflite', 'wb').write(tfmodel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import *\n",
        "model.fit(x_train, y_train)\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQlHWcgtNqQc",
        "outputId": "ee1b1e21-0fb0-4c28-aef8-8fd52dc5782d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.9958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://66d2531d-eaed-45ac-aaa0-528ba6d63358/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://66d2531d-eaed-45ac-aaa0-528ba6d63358/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8e13396a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8e187c9590> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import *\n",
        "model.fit(x_train, y_train)\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.pkl'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rptzpMUVPg5n",
        "outputId": "374442ba-cc03-4335-fdcf-783d403831f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0137 - accuracy: 0.9958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://dd7b9c57-9130-48b5-82b1-e1c12f01e11d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://dd7b9c57-9130-48b5-82b1-e1c12f01e11d/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8e13396a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8e187c9590> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xxX_zI6zcW2",
        "outputId": "6cb02dec-424c-425b-f7b1-320e82365772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 input(s):\n",
            "[ 1 11] <class 'numpy.float32'>\n",
            "\n",
            "1 output(s):\n",
            "[ 1 14] <class 'numpy.float32'>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Print input shape and type\n",
        "inputs = interpreter.get_input_details()\n",
        "print('{} input(s):'.format(len(inputs)))\n",
        "for i in range(0, len(inputs)):\n",
        "    print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))\n",
        "\n",
        "# Print output shape and type\n",
        "outputs = interpreter.get_output_details()\n",
        "print('\\n{} output(s):'.format(len(outputs)))\n",
        "for i in range(0, len(outputs)):\n",
        "    print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDlSY_7Z90Oh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import string\n",
        "import random\n",
        "\n",
        "def chat(user_text, kondisiRumah_array):\n",
        "  texts_p = []\n",
        "  kondisiLampu = kondisiRumah_array[0] \n",
        "  kondisiPintu = kondisiRumah_array[1] \n",
        "  kondisiJemuran = kondisiRumah_array[2] \n",
        "  kondisiGas = kondisiRumah_array[3] \n",
        "  # Check kondisi lampu\n",
        "  if kondisiLampu==False:\n",
        "    kondisiLampu='mati'\n",
        "  else:\n",
        "    kondisiLampu='nyala'\n",
        "    # Check kondisi pintu\n",
        "  if kondisiPintu==False:\n",
        "    kondisiPintu='terbuka'\n",
        "  else:\n",
        "    kondisiPintu='terkunci'\n",
        "  # Check kondisi jemuran\n",
        "  if kondisiJemuran==False:\n",
        "    kondisiJemuran='kehujanan'\n",
        "  else:\n",
        "    kondisiJemuran='aman'\n",
        "  # Check kondisi gas\n",
        "  if kondisiGas==False:\n",
        "    kondisiGas='mati'\n",
        "  else:\n",
        "    kondisiGas='nyala'\n",
        "\n",
        "  #removing punctuation and converting to lowercase\n",
        "  prediction_input = [letters.lower() for letters in user_text if letters not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "\n",
        "  #tokenizing and padding\n",
        "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input],input_shape)\n",
        "\n",
        "  #getting output from model\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "  response_tag = lbl_encoder.inverse_transform([output])[0]\n",
        "\n",
        "  #finding the right tag and predicting\n",
        "  response_tag = lbl_encoder.inverse_transform([output])[0]\n",
        "  if response_tag == \"perpisahan\":\n",
        "    print(\"Aweshome : \",random.choice(responses['perpisahan']))\n",
        "  elif response_tag == \"kondisi_rumah\":\n",
        "    #lampu, pintu, jemuran, gas = getSensor()\n",
        "    kondisiRumah = []\n",
        "    print(\"Aweshome: kondisi lampu\", kondisiLampu, \", kondisi pintu\", kondisiPintu, \", kondisi jemuran\", kondisiJemuran, \", dan kondisi gas\", kondisiGas)\n",
        "    text = input(\"You: \")\n",
        "    chat(text, kondisiRumah_array)\n",
        "  else:\n",
        "    print(\"Aweshome : \",random.choice(responses[response_tag]))\n",
        "    text = input(\"You: \")\n",
        "    chat(text, kondisiRumah_array) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"You: \")\n",
        "kondisi = [False, False, True, False]\n",
        "chat(inp, kondisi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHvxHg2lvSA9",
        "outputId": "a51b539f-d7ce-4da8-99cf-b555e283cfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: bagaimana kondisi lampu saat ini\n",
            "Aweshome: kondisi lampu mati , kondisi pintu terbuka , kondisi jemuran aman , dan kondisi gas mati\n",
            "You: bye\n",
            "Aweshome :  Sampai jumpa\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Fix Bismillah aweshome_chatbot",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}